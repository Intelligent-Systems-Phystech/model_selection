{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Copy of main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEEBmcuNZC2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwsSksRqfr5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mathpl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kQmtwT7ZC2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO9-jAA9ZC2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrQdFwZZC24",
        "colab_type": "code",
        "outputId": "e2a18469-2afa-4557-c9ac-8835252abf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHH_pS5SZC2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = 128\n",
        "n = 3\n",
        "\n",
        "w = np.random.randn(n)\n",
        "\n",
        "X_train = np.random.randn(m, n)\n",
        "Y_train = (X_train@w).reshape([-1, 1])\n",
        "\n",
        "X_test = np.random.randn(m, n)\n",
        "Y_test = (X_test@w).reshape([-1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqO-hrcZC3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(torch.Tensor(X_train), torch.Tensor(Y_train))\n",
        "test_data = TensorDataset(torch.Tensor(X_test), torch.Tensor(Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-AFKkq2ZC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_ts, Y_ts = test_data[:]\n",
        "\n",
        "X_tr, Y_tr = train_data[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMjcQHu6ZC3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
        "    '''\n",
        "    Compute the gradient of `outputs` with respect to `inputs`\n",
        "    gradient(x.sum(), x)\n",
        "    gradient((x * y).sum(), [x, y])\n",
        "    '''\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "\n",
        "def jacobian(outputs, inputs, create_graph=False):\n",
        "    '''\n",
        "    Compute the Jacobian of `outputs` with respect to `inputs`\n",
        "    jacobian(x, x)\n",
        "    jacobian(x * y, [x, y])\n",
        "    jacobian([x * y, x.sqrt()], [x, y])\n",
        "    '''\n",
        "    if torch.is_tensor(outputs):\n",
        "        outputs = [outputs]\n",
        "    else:\n",
        "        outputs = list(outputs)\n",
        "\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "\n",
        "    jac = []\n",
        "    for output in outputs:\n",
        "        output_flat = output.view(-1)\n",
        "        output_grad = torch.zeros_like(output_flat)\n",
        "        for i in range(len(output_flat)):\n",
        "            output_grad[i] = 1\n",
        "            jac += [gradient(output_flat, inputs, output_grad, True, create_graph)]\n",
        "            output_grad[i] = 0\n",
        "    return torch.stack(jac)\n",
        "\n",
        "def hessian(output, inputs, out=None, allow_unused=False, create_graph=False):\n",
        "    '''\n",
        "    Compute the Hessian of `output` with respect to `inputs`\n",
        "    hessian((x * y).sum(), [x, y])\n",
        "    '''\n",
        "    assert output.ndimension() == 0\n",
        "\n",
        "    if torch.is_tensor(inputs):\n",
        "        inputs = [inputs]\n",
        "    else:\n",
        "        inputs = list(inputs)\n",
        "\n",
        "    n = sum(p.numel() for p in inputs)\n",
        "    if out is None:\n",
        "        out = output.new_zeros(n, n)\n",
        "\n",
        "    ai = 0\n",
        "    for i, inp in enumerate(inputs):\n",
        "        [grad] = torch.autograd.grad(output, inp, create_graph=True, allow_unused=allow_unused)\n",
        "        grad = torch.zeros_like(inp) if grad is None else grad\n",
        "        grad = grad.contiguous().view(-1)\n",
        "\n",
        "        for j in range(inp.numel()):\n",
        "            if grad[j].requires_grad:\n",
        "                row = gradient(grad[j], inputs[i:], retain_graph=True, create_graph=create_graph)[j:]\n",
        "            else:\n",
        "                row = grad[j].new_zeros(sum(x.numel() for x in inputs[i:]) - j)\n",
        "\n",
        "            out[ai, ai:].add_(row.type_as(out))  # ai's row\n",
        "            if ai + 1 < n:\n",
        "                out[ai + 1:, ai].add_(row[1:].type_as(out))  # ai's column\n",
        "            del row\n",
        "            ai += 1\n",
        "        del grad\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "non2f-LKZC3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural(nn.Module):\n",
        "    def __init__(self, input_dim=10, hidden_dim=3, output_dim=1, device='cpu'):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super(Neural, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.device = device\n",
        "\n",
        "#         self.body = nn.Sequential(\n",
        "#             nn.Linear(self.input_dim, self.hidden_dim),\n",
        "#             nn.LeakyReLU(),\n",
        "#         )\n",
        "        \n",
        "        self.head = nn.Linear(self.input_dim, self.output_dim)\n",
        "        \n",
        "        list_of_w = []\n",
        "        for w in self.parameters():\n",
        "            list_of_w.append(w.data.view(-1))\n",
        "        self.D = len(torch.cat(list_of_w))\n",
        "        self.S = 0.5*self.D*(1+2*math.pi)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "        \n",
        "    def predict(self, input):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input: Tensor(batch_size x input_dim) --- the matrix of input data\n",
        "            \n",
        "        Returns:\n",
        "            Tensor(batch_size x output_dim) --- the matrix of output data\n",
        "        \n",
        "        \"\"\"\n",
        "#         out = self.body(input)\n",
        "        return self.head(input)\n",
        "    \n",
        "    def log_prior_w(self, w):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        sigma = 0.\n",
        "        w = w.view(-1)\n",
        "        return -0.5*(sigma**2)*torch.dot(w, w)\n",
        "      \n",
        "    def log_priot_all(self):\n",
        "        temp = 0\n",
        "        for w in self.parameters():\n",
        "            temp += self.log_prior_w(w)\n",
        "        return temp\n",
        "     \n",
        "    def loglikelihood(self, batch_x, batch_y):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        beta = 10\n",
        "        D = len(batch_y)\n",
        "        return -0.5*beta*torch.sum((self.predict(batch_x) - batch_y)**2)\n",
        "    \n",
        "    def margin_likelihood(self, batch_x, batch_y):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        temp = self.log_priot_all() + self.loglikelihood(batch_x, batch_y)\n",
        "        return temp\n",
        "    \n",
        "    def loss(self, batch_x, batch_y):\n",
        "      out = self.predict(batch_x)\n",
        "#       return torch.nn.MSELoss()(out, batch_y)\n",
        "      return torch.mean((out - batch_y)**2)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8rqVYjPZC3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Neural(input_dim=n, output_dim=1)\n",
        "List_of_step = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ZCAm7lZC3R",
        "colab_type": "code",
        "outputId": "06f981b3-f7f7-4fa2-ff26-12c627b89e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alpha = 0.0001\n",
        "\n",
        "\n",
        "\n",
        "for ep in tqdm(range(1000)):\n",
        "    generator = DataLoader(train_data, batch_size=4, shuffle=True)\n",
        "    for batch_x, batch_y in generator:\n",
        "        # оптимизация энтропии\n",
        "        model.zero_grad()\n",
        "        margin_likelihood = -model.margin_likelihood(batch_x, batch_y)\n",
        "\n",
        "        list_of_w = []\n",
        "        for w in model.parameters():\n",
        "            list_of_w.append(w)\n",
        "\n",
        "        model.S = (model.S+torch.log(torch.det(torch.eye(model.D) - alpha*hessian(margin_likelihood, list_of_w)))).detach()\n",
        "\n",
        "        # оптимизация параметров сетки     \n",
        "        model.zero_grad()\n",
        "\n",
        "        optimazer = optim.SGD(model.parameters(), lr=alpha)\n",
        "\n",
        "        loss = model.loss(batch_x, batch_y)\n",
        "        loss.backward()\n",
        "\n",
        "        #         \n",
        "\n",
        "        #         for w in model.parameters():\n",
        "        #           w.data = (w.data - alpha*w.grad).detach()\n",
        "\n",
        "\n",
        "\n",
        "        optimazer.step()\n",
        "\n",
        "    List_of_step.append((model.S.item(), model.log_priot_all().item(), model.loglikelihood(X_tr, Y_tr).item(), model.loglikelihood(X_ts, Y_ts).item()))\n",
        "        \n",
        "        \n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:58<00:00,  8.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Prm65Zfqnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV0ag_4uwbUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f7178bb-3a92-4393-dc44-4fba1dc40b76"
      },
      "source": [
        "model.S"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-521.5541)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ4cdStZZC3T",
        "colab_type": "code",
        "outputId": "9e37e478-64ad-406c-ef26-812312e75d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((model.predict(X_ts) - Y_ts)**2).mean()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4032e-05, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRQhVe97y3kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c946e187-8a47-4329-981d-7d0269bc9ac8"
      },
      "source": [
        "((model.predict(X_tr) - Y_tr)**2).mean()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.3127e-05, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ILOzDI0Cfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}