{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEEBmcuNZC2j"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwsSksRqfr5d"
   },
   "outputs": [],
   "source": [
    "from utils import gradient, jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_MrQdFwZZC24",
    "outputId": "e2a18469-2afa-4557-c9ac-8835252abf0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Setings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['lines.markersize'] = 6\n",
    "plt.rcParams['xtick.labelsize'] = 36\n",
    "plt.rcParams['ytick.labelsize'] = 36\n",
    "plt.rcParams['legend.fontsize'] = 36\n",
    "plt.rcParams['axes.titlesize']=36\n",
    "plt.rcParams['axes.labelsize']=36\n",
    "plt.rcParams['figure.figsize'] = (24.0, 12.0)\n",
    "plt.rcParams['font.size'] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHH_pS5SZC2_"
   },
   "outputs": [],
   "source": [
    "m = 128\n",
    "n = 3\n",
    "\n",
    "w = np.random.randn(n)\n",
    "\n",
    "X_train = np.random.randn(m, n)\n",
    "Y_train = (X_train@w).reshape([-1, 1])\n",
    "\n",
    "X_test = np.random.randn(m, n)\n",
    "Y_test = (X_test@w).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYqO-hrcZC3D"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.Tensor(X_train).to(device), torch.Tensor(Y_train).to(device))\n",
    "test_data = TensorDataset(torch.Tensor(X_test).to(device), torch.Tensor(Y_test).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-AFKkq2ZC3L"
   },
   "outputs": [],
   "source": [
    "X_ts, Y_ts = test_data[:]\n",
    "\n",
    "X_tr, Y_tr = train_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "non2f-LKZC3O"
   },
   "outputs": [],
   "source": [
    "class Neural(nn.Module):\n",
    "    def __init__(self, input_dim=10, hidden_dim=3, output_dim=1, device='cpu'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(Neural, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.device = device\n",
    "\n",
    "#         self.body = nn.Sequential(\n",
    "#             nn.Linear(self.input_dim, self.hidden_dim),\n",
    "#             nn.LeakyReLU(),\n",
    "#         )\n",
    "        \n",
    "        self.head = nn.Linear(self.input_dim, self.output_dim)\n",
    "        \n",
    "        list_of_w = []\n",
    "        for w in self.parameters():\n",
    "            list_of_w.append(w.data.view(-1))\n",
    "        self.D = len(torch.cat(list_of_w))\n",
    "        self.S = torch.Tensor([0.5*self.D*(1+2*math.pi)]).mean().to(device)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "        \n",
    "    def predict(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: Tensor(batch_size x input_dim) --- the matrix of input data\n",
    "            \n",
    "        Returns:\n",
    "            Tensor(batch_size x output_dim) --- the matrix of output data\n",
    "        \n",
    "        \"\"\"\n",
    "#         out = self.body(input)\n",
    "        return self.head(input)\n",
    "    \n",
    "    def log_prior_w(self, w):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sigma = 1.\n",
    "        w = w.view(-1)\n",
    "        return -0.5*(sigma**2)*torch.dot(w, w)-0.5*len(w)*math.log(2*math.pi)+len(w)*math.log(sigma)\n",
    "      \n",
    "    def log_priot_all(self):\n",
    "        temp = 0\n",
    "        for w in self.parameters():\n",
    "            temp += self.log_prior_w(w)\n",
    "        return temp\n",
    "     \n",
    "    def loglikelihood(self, batch_x, batch_y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        beta = 1\n",
    "        D = len(batch_y)\n",
    "        return -0.5*beta*torch.sum((self.predict(batch_x) - batch_y)**2)- 0.5*D*math.log(2*math.pi) + 0.5*D*math.log(beta)\n",
    "    \n",
    "    def margin_likelihood(self, batch_x, batch_y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        temp = self.log_priot_all() + self.loglikelihood(batch_x, batch_y)\n",
    "        return temp\n",
    "    \n",
    "    def loss(self, batch_x, batch_y):\n",
    "        out = self.predict(batch_x)\n",
    "#       return torch.nn.MSELoss()(out, batch_y)\n",
    "        return torch.mean((out - batch_y)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K_ZCAm7lZC3R",
    "outputId": "06f981b3-f7f7-4fa2-ff26-12c627b89e82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1000 [00:04<00:56, 16.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c47be173a8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlist_of_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargin_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# оптимизация параметров сетки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/model_selection/Grabovoy/practice/utils.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(output, inputs, out, allow_unused, create_graph)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/model_selection/Grabovoy/practice/utils.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                 \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                 create_graph=create_graph)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Neural(input_dim=n, output_dim=1)\n",
    "List_of_step = []\n",
    "\n",
    "alpha = 0.0001\n",
    "\n",
    "for ep in tqdm(range(1000)):\n",
    "    generator = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "    for batch_x, batch_y in generator:\n",
    "        bh_size = len(batch_y)\n",
    "        \n",
    "        # оптимизация энтропии\n",
    "        model.zero_grad()\n",
    "        margin_likelihood = -model.margin_likelihood(batch_x, batch_y)\n",
    "\n",
    "        list_of_w = []\n",
    "        for w in model.parameters():\n",
    "            list_of_w.append(w)\n",
    "            \n",
    "        model.S = (model.S+torch.log(torch.det(torch.eye(model.D, device=device) - alpha*hessian(margin_likelihood, list_of_w)))).detach()\n",
    "\n",
    "        # оптимизация параметров сетки     \n",
    "        model.zero_grad()\n",
    "\n",
    "        optimazer = optim.SGD(model.parameters(), lr=alpha)\n",
    "\n",
    "        loss = model.loss(batch_x, batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimazer.step()\n",
    "\n",
    "    List_of_step.append((model.S.item(), model.log_priot_all().item(), model.loglikelihood(batch_x, batch_y).item()))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([item[1]+item[2] for item in List_of_step[600:]], label = 'Train')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
