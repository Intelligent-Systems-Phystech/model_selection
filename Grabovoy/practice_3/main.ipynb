{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDUVA7WCIWde"
   },
   "outputs": [],
   "source": [
    "from zlib import crc32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_ecEqR2qIWdl",
    "outputId": "adafe6ab-aac0-422c-8176-5f4ce4936d75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crc32('грабовой'.lower().encode('utf-8'))%5+1, crc32('grabovoy'.lower().encode('utf-8'))%3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRw7tB2F_kvg"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5mJHz-6BGj2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-xH14pMIWdr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYh-uWuv-xsj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezKBGTrTIWdy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "eOVW8XKdIWd2",
    "outputId": "72a25541-26db-4000-8817-359f6e5dbd2a"
   },
   "outputs": [],
   "source": [
    "MNIST = datasets.MNIST('./mnist', train=False, download=True, transform=None)\n",
    "X_test, Y_test = MNIST.test_data, MNIST.test_labels\n",
    "\n",
    "MNIST = datasets.MNIST('./mnist', train=True, download=True, transform=None)\n",
    "X_train, Y_train = MNIST.train_data, MNIST.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MECG-LbtIWd4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([X_train.shape[0], -1]).float()\n",
    "X_test = X_test.reshape([X_test.shape[0], -1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CM1Tt6gsIWd7",
    "outputId": "0bf794f6-077e-441b-beef-948fddcfccb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c50HSjxgIWd9"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IELWT_-JnExw"
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://github.com/mariogeiger/hessian #\n",
    "##########################################\n",
    "#                                        #\n",
    "# Данные функции были взяты из интернета #\n",
    "#                                        #\n",
    "##########################################\n",
    "\n",
    "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
    "    '''\n",
    "    Compute the gradient of `outputs` with respect to `inputs`\n",
    "    gradient(x.sum(), x)\n",
    "    gradient((x * y).sum(), [x, y])\n",
    "    '''\n",
    "    if torch.is_tensor(inputs):\n",
    "        inputs = [inputs]\n",
    "    else:\n",
    "        inputs = list(inputs)\n",
    "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
    "                                allow_unused=True,\n",
    "                                retain_graph=retain_graph,\n",
    "                                create_graph=create_graph)\n",
    "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
    "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
    "\n",
    "def hessian(output, inputs, out=None, allow_unused=False, create_graph=False):\n",
    "    '''\n",
    "    Compute the Hessian of `output` with respect to `inputs`\n",
    "    hessian((x * y).sum(), [x, y])\n",
    "    '''\n",
    "    assert output.ndimension() == 0\n",
    "\n",
    "    if torch.is_tensor(inputs):\n",
    "        inputs = [inputs]\n",
    "    else:\n",
    "        inputs = list(inputs)\n",
    "\n",
    "    n = sum(p.numel() for p in inputs)\n",
    "    if out is None:\n",
    "        out = output.new_zeros(n, n)\n",
    "\n",
    "    ai = 0\n",
    "    for i, inp in enumerate(inputs):\n",
    "        [grad] = torch.autograd.grad(output, inp, create_graph=True, allow_unused=allow_unused)\n",
    "        grad = torch.zeros_like(inp) if grad is None else grad\n",
    "        grad = grad.contiguous().view(-1)\n",
    "\n",
    "        for j in range(inp.numel()):\n",
    "            if grad[j].requires_grad:\n",
    "                row = gradient(grad[j], inputs[i:], retain_graph=True, create_graph=create_graph)[j:]\n",
    "            else:\n",
    "                row = grad[j].new_zeros(sum(x.numel() for x in inputs[i:]) - j)\n",
    "\n",
    "            out[ai, ai:].add_(row.type_as(out))  # ai's row\n",
    "            if ai + 1 < n:\n",
    "                out[ai + 1:, ai].add_(row[1:].type_as(out))  # ai's column\n",
    "            del row\n",
    "            ai += 1\n",
    "        del grad\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим модель логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sU4N4hkIWd-"
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_dim = 20, output_dim = 10, device = 'cpu'):\n",
    "        super(LogReg, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = input\n",
    "        out = F.relu(out)\n",
    "        return self.linear(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tL9H_7P_IWd_"
   },
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим все функции для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veyRL9LKIWd_"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch_of_x)\n",
    "        \n",
    "        loss = loss_function(output, batch_of_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     \n",
    "        return\n",
    "    \n",
    "def train_epoch(train_generator, model, loss_function, optimizer):\n",
    "    model.train()\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "\n",
    "    return\n",
    "\n",
    "def trainer(count_of_epoch, \n",
    "            batch_size, \n",
    "            dataset,\n",
    "            model, \n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            progress = None\n",
    "           ):\n",
    "    iterations = range(count_of_epoch)\n",
    "    if progress is not None:\n",
    "        iterations = progress(iterations)\n",
    "\n",
    "    for it in iterations:\n",
    "        optima = optimizer\n",
    "\n",
    "        batch_generator = DataLoader(dataset = dataset, batch_size = batch_size, shuffle=True)\n",
    "        \n",
    "        train_epoch(train_generator = batch_generator, model = model, loss_function = loss_function, optimizer = optima)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYhvcbLmIWeA"
   },
   "source": [
    "# Переопределеный оптимизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переопределим оптимизатор, чтобы оптимизировать только те переменые, которые не были удалены из модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7J43Um9tIWeA"
   },
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adam, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "            \n",
    "# ==================================================\n",
    "# Additition function\n",
    "    def get_masks(self, kind = 'prune'):\n",
    "        list_of_mask = []\n",
    "        LIST_prune = []\n",
    "        mask_vector = None\n",
    "        if kind == 'prune':\n",
    "            for group in self.param_groups:\n",
    "                 for p in group['params']:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'prune' not in param_state:\n",
    "                        param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                    p_vector = p.view(-1)\n",
    "                    prune_vector = param_state['prune'].view(-1)\n",
    "                    LIST_prune.append(prune_vector)\n",
    "        mask_vector = torch.cat(LIST_prune)\n",
    "        return mask_vector\n",
    "\n",
    "    def prune(self, amount = 0.1, method='random', **argv):\n",
    "        if method == 'random':\n",
    "            for group in self.param_groups:\n",
    "                 for p in group['params']:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'prune' not in param_state:\n",
    "                        param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                    p_vector = p.view(-1)\n",
    "                    prune_vector = param_state['prune'].view(-1)\n",
    "                    if int(amount*len(p_vector)) > 0:\n",
    "                        prune_vector[torch.randperm(p_vector.shape[0])[:int(amount*len(p_vector))]] = 0\n",
    "                        p_vector.data.mul_(prune_vector)\n",
    "\n",
    "        elif method == 'OBD':\n",
    "            if argv['hessian'] is None:\n",
    "                pass\n",
    "            else:\n",
    "                for group in self.param_groups:\n",
    "                    for p, h in zip(group['params'], argv['hessian']):\n",
    "                        param_state = self.state[p]\n",
    "                        if 'prune' not in param_state:\n",
    "                            param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                        p_vector = p.view(-1)\n",
    "                        score = (p*h).view(-1)\n",
    "                        prune_vector = param_state['prune'].view(-1)\n",
    "                        if int(amount*len(p_vector)) > 0:\n",
    "                            prune_vector[torch.sort(score)[1][:int(amount*len(p_vector))]] = 0\n",
    "                            p_vector.data.mul_(prune_vector)\n",
    "\n",
    "            pass\n",
    "    \n",
    "    def deprune(self):\n",
    "        for group in self.param_groups:\n",
    "             for p in group['params']:\n",
    "                param_state = self.state[p]\n",
    "                param_state['prune'] = torch.ones_like(p)\n",
    "# ==================================================\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                    \n",
    "# ==================================================\n",
    "# Addition in each step\n",
    "                d_p = p.grad.data.detach()\n",
    "                param_state = self.state[p]\n",
    "    \n",
    "                if 'prune' in param_state:\n",
    "                    prune = param_state['prune']\n",
    "                else:\n",
    "                    prune = torch.ones_like(p)\n",
    "                    param_state['prune'] = prune\n",
    "# ==================================================                   \n",
    "                    \n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if 'step' not in state:\n",
    "                    state['step'] = 0\n",
    "                # Exponential moving average of gradient values\n",
    "                if 'exp_avg' not in state:\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                # Exponential moving average of squared gradient values\n",
    "                if 'exp_avg_sq' not in state:\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                if amsgrad:\n",
    "                    # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                    if 'max_exp_avg_sq' not in state:\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                \n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad.add_(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                if amsgrad:\n",
    "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    # Use the max. for normalizing running avg. of gradient\n",
    "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                else:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "\n",
    "                    \n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                step_size = group['lr'] * (bias_correction2**(0.5)) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, prune*exp_avg, denom)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-de7oKsIWeB"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SpRX1OD_IWeC",
    "outputId": "9b7c81cd-09a0-4bf1-ca1c-d2fe12ae0b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47AcefhNIWeE"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2Pte2nfIWeF"
   },
   "outputs": [],
   "source": [
    "TRAIN = TensorDataset(X_train.to(device), Y_train.to(device))\n",
    "TEST = TensorDataset(X_test.to(device), Y_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAYSy-dZIWeG"
   },
   "outputs": [],
   "source": [
    "model = LogReg(input_dim=X_train.shape[1], output_dim = 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcykU8MDIWeG"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VXz5GEQ9IWeI",
    "outputId": "558bc9c6-5e10-457e-d17a-dadd6bfb5894"
   },
   "outputs": [],
   "source": [
    "# trainer(count_of_epoch = 100,\n",
    "#         batch_size = 64,\n",
    "#         dataset = TRAIN,\n",
    "#         model = model,\n",
    "#         loss_function = loss_function,\n",
    "#         optimizer = optimizer,\n",
    "#         progress = tqdm\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n2QdIc7-FnH"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'train_model.sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "An5G7SSRIWeJ"
   },
   "outputs": [],
   "source": [
    "output = model(TRAIN[:][0])\n",
    "\n",
    "loss = loss_function(output, TRAIN[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ng4dPeRmtEln"
   },
   "outputs": [],
   "source": [
    "def resize_hess(model, hess):\n",
    "    bias = 0\n",
    "    new_hess = []\n",
    "    for p in model.parameters():\n",
    "        p_size = torch.tensor(p.size()).prod()\n",
    "        new_hess.append(hess[bias:bias+p_size].view_as(p))\n",
    "        bias+=p_size\n",
    "    return new_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sYNkYmHpnLAB",
    "outputId": "a1a1dd4d-a3d8-44aa-d405-6ee0a1b0a3cc"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# hess = hessian(loss, model.parameters())\n",
    "\n",
    "# hhs = torch.diag(hess)\n",
    "# hs = resize_hess(model, hhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jcPYBa7_NlM"
   },
   "outputs": [],
   "source": [
    "# with open('hess.pkl', 'wb') as f:\n",
    "#     pickle.dump(hs, f)\n",
    "\n",
    "with open('dump/hess.pkl', 'rb') as f:\n",
    "    hs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xobJxrVP_H6p"
   },
   "outputs": [],
   "source": [
    "# files.download('train_model.sv')\n",
    "# files.download('hess.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "Tp0v1YVi_gqB",
    "outputId": "7473626a-7d04-407c-ef9e-295132ebe64d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:56<00:00, 11.68s/it]\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "amounts = np.linspace(0, 1, 10)\n",
    "k_for_averaging = 5\n",
    "\n",
    "List_of_random_score = []\n",
    "for amount in tqdm(amounts):\n",
    "    List_of_score = []\n",
    "    for _ in range(k_for_averaging):\n",
    "        model.load_state_dict(torch.load('dump/train_model.sv'))\n",
    "        optimizer = Adam(model.parameters())\n",
    "        optimizer.prune(amount=amount, method='random', hessian=hs)\n",
    "\n",
    "        trainer(count_of_epoch = 2,\n",
    "            batch_size = 64,\n",
    "            dataset = TRAIN,\n",
    "            model = model,\n",
    "            loss_function = loss_function,\n",
    "            optimizer = optimizer\n",
    "        )\n",
    "\n",
    "        output = model(TEST[:][0])\n",
    "        output.sum(dim = 1)\n",
    "        answ = torch.argmax(torch.softmax(output, dim = 1), dim = 1)\n",
    "\n",
    "        List_of_score.append(float((TEST[:][1] == answ).sum())/TEST[:][1].shape[0])\n",
    "    List_of_random_score.append(List_of_score)\n",
    "  \n",
    "List_of_random_score = np.array(List_of_random_score)\n",
    "\n",
    "\n",
    "List_of_OBD_score = []\n",
    "for amount in tqdm(amounts):\n",
    "    model.load_state_dict(torch.load('dump/train_model.sv'))\n",
    "    optimizer = Adam(model.parameters())\n",
    "    optimizer.prune(amount=amount, method='OBD', hessian=hs)\n",
    "\n",
    "    trainer(count_of_epoch = 2,\n",
    "        batch_size = 64,\n",
    "        dataset = TRAIN,\n",
    "        model = model,\n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer\n",
    "    )\n",
    "\n",
    "    output = model(TEST[:][0])\n",
    "    output.sum(dim = 1)\n",
    "    answ = torch.argmax(torch.softmax(output, dim = 1), dim = 1)\n",
    "\n",
    "    List_of_OBD_score.append(float((TEST[:][1] == answ).sum())/TEST[:][1].shape[0])\n",
    "  \n",
    "List_of_OBD_score = np.array(List_of_OBD_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYU8pQfjBKrV"
   },
   "outputs": [],
   "source": [
    "random_mean = np.mean(List_of_random_score, axis = 1)\n",
    "random_std = np.std(List_of_random_score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "oSJPNaJv9Z4o",
    "outputId": "19f929de-65a0-40bd-99e1-08f41433e495"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xc1X3v/c9vz1V3yZIt25IsycaA7zaWL4RLTaEJhD4mIfQEzqttSELcpKVNQnohT/skgSY5TQ9JTpvynMRJaC4nxCFpmschJpAGhCGEiw3EYBuwbIwt46tsSxpJo7n9nj/2SB7JsiXL3hrNzO/9es1r9t6zZu+1JHu+2mvN3ktUFWOMMYXLyXYFjDHGZJcFgTHGFDgLAmOMKXAWBMYYU+AsCIwxpsD5s12Bc1VTU6NNTU3jem9PTw8lJSUXtkKTnLW5MFibC8P5tHnr1q3HVHXqSK/lXBA0NTWxZcuWcb23tbWVNWvWXNgKTXLW5sJgbS4M59NmEXnrTK9Z15AxxhQ4CwJjjClwFgTGGFPgLAiMMabAWRAYY0yB8zQIROR6EXldRNpE5O4RXm8UkV+LyDYRaRWRei/rY4wx5nSeBYGI+ID7gRuA+cBtIjJ/WLH7gO+p6mLgXuB/eFUfY4wxI/PyjGAl0Kaqe1Q1BmwAbhpWZj7weHr5iRFeN8YY4zHxaj4CEbkFuF5V70iv/wmwSlXvzCjzIPCcqv6LiNwM/AdQo6odw/a1DlgHUFtbu3zDhg3jqlMkEqG0tHRc7x2NnraQueguDf9Rj/iT1xHed9Z9D9umQ1+NRXsJhItH2LdLBMRdQmTkbTJYVtzljG2TkZe/58nK2lwYzqfN11xzzVZVbRnptWxfWfzXwL+JyO3AZuAAkBxeSFXXA+sBWlpadDxX1j3/7GbeeH4zgZIKxPGB4x98iM8H4m4Txwc+P+L4ESeA+BxwAojjQ/x+RHyIL4A4fnwD5fx+fL4APp8vvRzEcRxExvdxOfxd5/OhG9/3CoG6heexh1PhMVKIOI7gdwSfCD5H8PsERwS/4+BzZMjDP8K647jhMhAyg2E0EEUy9HjDtw+899QyPPnkk3bFaQGwNl84XgbBAaAhY70+vW2Qqr4N3AwgIqXA+1T1pBeVCbz5a9b1fgN6vdj76VIqJHHSDx9J8ZFKL8cIEHFKiThl9Dpl9PnKiPrKiPrL6A9UEAuUkwiWkwhWkAxWkAxXosFyQgE/Ib+PYMAh5HcI+txnvy87X/5ShXg8RU8yRTyZIp5UYskU8UTKfR7YlkiRSA5sc9fjKbdcPKkkVdNnK0p6kYEz1cx1zTiuopBKIZrCIYWjCURTCCnoOcH3Xvk5jibd10jipNxlNIWPJELSfV1TOJrCJ0nKAkJ52KEi5KMiJFQU+agMO1SE3fWgD/y4x/OLIpqEVAo0CanksOf0dk0Ne234+rB9oOALgT8E/jAEwu7zwPoZnsu6dsHhqSOXcfxDE9WYYbwMgheAuSLSjBsAtwL/PbOAiNQAx1U1BXwaeMCryiy7+a/57RMLWb2yhUQiQTKRIJGMk4jHiMViRONx4v0xYvE48XiMeDxBIhEnEY+7z8kEyUScVCKBppKQSkAqnl4eWE8M/ueW9LLowHP6kUriT0UpTnVTkopQF3+L0liEMnoIET9j/VMqdFNEp5bQSQkntZROSjiuJXRRSo9TSq9TSo+v/FSo+MuJJgXd20Yw4Cfodwj5fW6I+N3wiCWGfogPfmAn9NSHeSIJiSi+ZD9OMoqT6sefjOKkYgRT/YQlRpgYYeKEBpfTD4lRTnxwOZTxWpHECUmcAEn8uB/UflI4ksKH+4HtS3/wusuaLjPwAX+Wbs0JCvzRqDjps00fiIOID5zMbZnPDiCQjEEiCol+9zmVGPU4ywFePMOL4owhTIqGrocrYEozTJkD1XOgvM6tp8lLngWBqiZE5E7gUcAHPKCq20XkXmCLqm4E1gD/Q0QUt2voL7yqD6Ey+sNTkSnNBIDAOHeTSimJlJJIuR+eiWSKREqJJ1MkkqdeSyTT24a8liKVcvu+utOPTE4iij/eiRM9AX0nkWgn0n8Sp78Tf/9J/LEugvEuwvEuGuNdhBMHKUp2U5Tsxk/6wyKZfsRO7TfZ49BNMZ1awkktoVNL6KKEJE7Gh3KMsMTd5/QHdyjjcRpf+jGKpPhJOiGSvhApX5iUL4ym/9KVQCXiD4MvkPFh6HeffX73A8w51WWn4iPp+Ek6zqluPMeHpN8jPrfsW3v30nzRxRll3OeBbj9n4D3OwDH84LiRE08J3bEUR3uSHOtN0NGToKM3wfG+JMf7kpzoS9IVVU72J+mMpuhLQMZ5B0kcFIeicJDSUJDy4gDl4QAVRe5zZUmAKcVBqkuD1JQGmVISIhzwEfA5BHxCwOfgdwS/z+1aC/gEH0kCqThOaiAgMkIi/bztpS0snjf3tO0jlR3xub976HrvcUj0Zfy+Q1DV5IbClNnp5/RyeV06xEyu8nSMQFU3AZuGbftMxvJPgJ94WYcLzXGEoCMEx/mFq1TK/Uu7P5GiP5Eklkgvx1PEkiH646X0J2YQT6ZOG1w+I1WcZB+BWBf+WCeBWCeBeCf+WBcceY2i4hICsZOE4l3UxTppjHXh6z+EkBr8YE75ygc/rJO+MDFfiGh6OeULkfKF0svhIcuZH/BJXwgCRQRCRQSKSgiGSgiHgoQD7llIOOCjOODD53jbTXEw0colq9ec8/scIJR+1JyhjKoO/r6iiSQne+Ic6urjcFc/RyNRjnbHON7TT2dfgq6+OF3ROLuPRujqSxBLpk7bnwiUhfyUFwWoCAcoLwpQFvZTFvZTHh5YDlAe9lNRHKAoGCDgBAfHY/yOgy8kHKxIUVyz0g0Ox93uvu6Git85tTwmqtB9EDp2w/Hd6ec97mP3425gDPCHoar5VEhkBkXZDAuJHJDtweKC4zhC2PERDvg423nJ4AdOIpUOi2TGcor+eJJY0l1XhJS/mH5/Mf3F04fsp8/3CkWzFl2QuotAyO8jHBj4UHfS66e2BbI0XjFRRCTdXh8VBKgtD3PJjLIhZVTdsI/G07+3eIpoPMGJ3jhHuqMc6YpxLNLPyV43KLr64nT1JeiMxjnUFaU7OnJoAIT8TkZAnAqJUF+M6ui+IQFSGvbjH+FD2OcTAk7GGccIwRHwCUWBaorqphFuvBInM7xTKeh+OyMcdkPHHuhog12/gmT/qbL+onQ4NJ8Kh8GQmG5jF5OEBcEklfmBczYDgRFLDpxVuCExECJvO0Io4LiBMcoZRjD9V3vI71AUPPVXfNjvI5QeoB7vN6EKiYikx2LOHvYDAT8QGIPBkUhxsjfGse4YJ3tjdEUTdEfjdEcTdEcTdKWXj/fEeKujl+5owh1w3/3maccoDvpGDI6B59KM4CgJ+XFG+P2KuP82ioPuv8eigI+iYDVF06cRbrhy6L/RVAq62t2AGAiKjt1w7A3Y9Zg7/jEgUHz6GcTAWUVprYXEBLIgyHFDAiN8+usnd/u4au7Uwb9ST3VDpXAy/8L3+4b+1Wc8F0wP2peN8HsbEE+miMbdkIimA959Tg52TyWTyvE9rxCvuXgwJAaCoysjQA51RnnjcISe/sSIw+wiUBpyg6GyKMD0ijDTK8LMqAgzvTxMRVFgxD8EHAfCfh/hYDokAtUU1UwjPOMKioMZZ4mpJHS2D+1q6tgNR3bC649AKuPLEsFS9yyidiE0Xek+KhstHDxiQVAghvyVepYPHjO5uIPIZw+L/kSS3xzxs3Bhbbob6lRgDJxlZJ4NJlNKpD9BJCMohgdIR0+MtrZj9CdOdVEVBXxuKKSDYWB5almIVAp6Y6ddAgS4XVFFg2cSUyiqmkp42hUUpYPD5wgkE9C5/1Q30/GBrqbH4Hc/dHdU0XAqFJquvBA/XpNmQWBMjgv5fTgiTDtDWmQOcA90QUUzziii8eSIXYeqyoneOIc6oxzs7ONQV5SDnVF2vN3FM7tPXfzvE2FqeYgZ5eFTZxHp5eKgn2RSiSTd4BlJMN0VWRSYQrh8KkU1V5wKjoADR1+DvU/D3qeGBMPq0DQ4cd2pYKhqvDA/0AJkQWBMnhs63jTymMVAWAycRfTFk0SiCUrCfqpLg8yfWT6kfF8syaGuqBsSXX0c7HSXt7V3uuMVaRVFgcGupcxupqqS4OB4RCz9JYjOEa6jKQ76qKuaxczlHyaw8iPuGMSx1+HNp+h+4aeEdz0Kv3swfbBZQ88YLBjGzILAGHPWLyckU0okmqC7Pz7YpeTzCc3BEpprSoaUTaRSHIvETp1FdEY51BXl+b3Hh3QdhfwOtRndSwNnELXl4SHfPOuNJdl1OMKeoz1MKw/RMKWY8mnzYNo8tvddzJqrrx56xvDGL08Phuar0mMMs7z54eUBCwJjzFn5HKGiOEBF8dCzib5Y0h1TSIdDpD9BXwz3r//yMEsbKgfLqipd6QFrt4vJDYndRyM89+bxwXIiUFN6qpvp0ullLKqrIJmCgyejHDwZpbwoQH1VkfsGx4Ha+e5j1Tr3jOFMwVA5C5quyhh8tmAYYEFgjBmXoqCPoqCPaRnb4skUPf2JwW8qRfoTRPrjpFJCRZF7hfUl04ded9GfSHKkq5+DGWMRhzqj7DzUxWM7DjNrSjFrl8xkSX0FIkJXX5wdfXGi/Ql2He6mvqqYomD6TGbEYNh5KhhefwRe/oFb1oJhkAWBMeaCCfgcKouDVBYHB7epKr2xZDoY4oMB0R93v5EU8vtomFJMw5TiIftKppRn3+zg4W0H+bcn2k4LBFV4q6OXfcd7mVISpL6qmJrS4NCvuDoO1C5wH6v+bIRg2JQRDI3DgqGBQmFBYIzxlIhQEnIvWMv87nIskaI76o47DIRDbyxBKv2NVZ8jXDGnhtXN1SMGwsUZd6jtiMToiMQoCvqoqyxiZmXR4I0VhxgpGI7syAiGX8DL/8ctmxkMl94I4fLT95cnLAiMMVkR9DtUl4aoLg0NbkullJ5YYjAcDndF6Y+nTgXCng4efsUNhIZS4Sbn5OAZArjjFm1HIuw5FmFaWZiGquLTxjaGcByYvtB9rP7omYNhxR1w45e9/pFkjQWBMWbScByhLBygLBxgRgXMmVrKm8d62He8BxCuuKiG1bPdQPj5i3v5tyfaaKx2zxAW150KhFQKd2C6M0pZ2E/9lGKml4dHv+HhSMHw3T+Et1/yvvFZZEFgjJm0fI5w0bRS6iqLeONwN0e7+90uo4tqWOJ/m98lZvLwtoN87fGRAwGgO5pg59td7DrczczKIuqriigOjvGjz3Fg5jJ44Vvu1c++/PzIzM9WGWPySlHQx5KGSjoi/bx+uJve/uRgIKyaPYVn9xznF6MEQiKp7OvoZV9HL1NKg9RXFTG1NDT6jRSnL3Jvu318N0y9xOOWZoen9wwWketF5HURaRORu0d4fZaIPCEiL4nINhF5t5f1McbkturSEKubq7m4tmxwMm+/43DlRTX843sWcPs7mujtT/K1x9v4/Kad/K795OC0p5mOR2Js29/Jb9o6ePNYD7HEyLf9BtwgADj0igctmhw8CwIR8QH3AzcA84HbRGT+sGL/ADykqstwp7L8f72qjzEmPziOMKu6mNKQnxmVp76FNDwQevoTowZCNJ5k95EIT7cd5dUDnZzsHWE2vpqLwReEQ9u8bFZWedk1tBJoU9U9ACKyAbgJ2JFRRoGB72RVAG97WB9jTB4RYMHMCuqrinnjcDedve69igYCYfXsKTy7+zgPv/I2X3u8jaZ0l9GiYV1GMHRwuTTspyFzcNkXgGnz8vqMwMsgqAP2Z6y3A6uGlfkc8JiI/CVQAlznYX2MMXmooijAiqYpvH2yj7YjkcFuHr/jcOXcGlbPORUI/zpKIABEMgaXZ1S4g8sl0xfB6790L1rIwzkRZKTTpQuyY5FbgOtV9Y70+p8Aq1T1zowyd6Xr8GURuRz4NrBQVVPD9rUOWAdQW1u7fMOGDeOqUyQSobS0dFzvzVXW5sJgbT5lYErX4ZIp5fnDKR59K0FHFGaVCTc0+Vgw5ewz74nAJUd/ydy2b/LM5f9OLDTlgrbjXJzP7/maa67ZqqotI73m5RnBASDzGu369LZMHwauB1DV34pIGHfe8COZhVR1PbAeoKWlRdesWTOuCrW2tjLe9+Yqa3NhsDYP1dOf4I3D3XREhvb5/34TXL0ixW93d/CLVw7yjVdio54hAMyaE4a2b/KO2WUwd+RjTgSvfs9efmvoBWCuiDSLSBB3MHjjsDL7gGsBRGQe7vXnRz2skzGmAJSE/CybVcWShkqKg0Nvre13HK6aO5XPv2chH7i8kUh/gn99vI0vbNrJtjMMKndVXOwu5OmAsWdnBKqaEJE7gUcBH/CAqm4XkXuBLaq6EfgU8E0R+STuwPHt6lVflTGm4EwtC1FdEuSt473sPdZDMnXq42UgEC6fUz14hnCmMYROLWZqVVPeDhh7ekGZqm4CNg3b9pmM5R3AFV7WwRhT2BxHaK4pYUZFmLYjEQ51Roe8PhgIs6t5Zk8Hm0YIhK5o3L2eIE+DwNMLyowxZrIIB3wsrKugpamKsvDpfwP7fQ5Xz53K529ayJ9e3kh39FSX0esHu2H6YujYDf2RLNTeWxYExpiCUlkcZGXzFC6dUUZghFtVDwTCF97jBsLhrn7+48V2YjULAHXvTppnLAiMMQVHRKivKuYdc6ppmFI84qUBA4Ewf0Y5b3X00lV5qftCHg4YWxAYYwpWwOdwyfQyVs2upqokOGKZxupijkb62Z+ogqKqvBwnsCAwxhS80pCf5Y1VLK6vIBwY+nXTpuoSALYd6MrbAWMLAmOMSZtWHubyOdU0Ty0ZnMSmsdqdS3n7253ugPHh7e7cBHnEgsAYYzL4HGHO1FIun1PNtPIQJSE/U8tC7D7SQ3zqglNzE+QRCwJjjBlBOOBjcX0lixsqaKouZm9HD5Gqee6LedY9ZEFgjDFnMa0szOyaEjp6YuyVurycm8CCwBhjRrGgrgKAlw/05OXcBBYExhgziiX1lQBsfzv9zaGD29y5CfKEBYExxoxiRmWY6eXuvYqS0xZB7zGIHM52tS4YCwJjjBlFRVGAxupi3urooWdK/g0YWxAYY8woQn4fF00r5URvnD1Oo7sxjwaMLQiMMWYMFs50B4xfPKyQZ3MTWBAYY8wYLGmoQARePdCZd7ea8DQIROR6EXldRNpE5O4RXv+qiLycfrwhIie9rI8xxozX9IqiwcltktMW5dXcBJ4FgYj4gPuBG4D5wG0iMj+zjKp+UlWXqupS4GvAT72qjzHGnI/ysJ+m6hL2dvTQN2Ue+TQ3gZdnBCuBNlXdo6oxYANw01nK3wb80MP6GGPMuPl9DnOnldIVTbDHP8fdmCcDxl7OWVwH7M9YbwdWjVRQRBqBZuDxM7y+DlgHUFtbS2tr67gqFIlExv3eXGVtLgzW5olRG48DsOnldub5yzj64mO80XPRhB3fqzZ7Onn9ObgV+ImqJkd6UVXXA+sBWlpadM2aNeM6SGtrK+N9b66yNhcGa/PEqDvczX1bN3PYX0ugYRkzY8eYOYF18KrNXnYNHQAaMtbr09tGcivWLWSMmeSmlYeZWVnEriPdpGoX5c3cBF4GwQvAXBFpFpEg7of9xuGFRORSoAr4rYd1McaY81YW8tNUU8LeY730TZmfN3MTeBYEqpoA7gQeBXYCD6nqdhG5V0TWZhS9Fdigmkd3cDLG5CXHES6dXkakP8Gb/tnuxjy4nsDTMQJV3QRsGrbtM8PWP+dlHYwx5kJaXOfeifS3XdUsHJibYNEtWa7V+bEri40x5hwsaajA5wivHurNm7kJLAiMMeYcTC0LUVdZxK7D3WhtfsxNYEFgjDHnoDjoZ3ZNCXs7eonWzM+LuQksCIwx5hzNm1lObyyZNwPGFgTGGHOOFte7t6R+rmeGuyHHbzVhQWCMMedocX0Ffkd48UgqL+YmsCAwxphzVFMaomFKMbsOR9A8mJvAgsAYY85RyO9jzlT3ltT91Qtyfm4CCwJjjBmHeTPKicZTvBWYQ67PTWBBYIwx47C0wb3C+PlonbshhweMLQiMMWYcFtVXEPAJzx0LQ1FVTo8TWBAYY8w4TCkOMmtKMW8cieT8ZPYWBMYYMw5+n8NF08p4q6OXWM2CnJ6bwILAGGPGacHMMvoTKd4KzsnpuQksCIwxZpyWNlQBsDVa727I0e4hCwJjjBmnRfUVhPwOT3dOgYG5CXKQp0EgIteLyOsi0iYid5+hzH8TkR0isl1EHvSyPsYYcyFVhAM0Vhfz2uG+nJ6bwLMgEBEfcD9wAzAfuE1E5g8rMxf4NHCFqi4APuFVfYwx5kJzHGFubRlvHe8lVrMwZ+cm8PKMYCXQpqp7VDUGbABuGlbmI8D9qnoCQFWPeFgfY4y54BbOrCCeVNpDc3J2bgIv5yyuA/ZnrLcDq4aVuRhARH4D+IDPqeovh+9IRNYB6wBqa2tpbW0dV4Uikci435urrM2FwdqcPWVdSQCeaPcxG9j22A84Xr3ck2N51WZPJ68f4/HnAmuAemCziCxS1ZOZhVR1PbAeoKWlRdesWTOug7W2tjLe9+Yqa3NhsDZnTyQa5wsv/JpXwksBWDwNuGqNJ8fyqs1edg0dABoy1uvT2zK1AxtVNa6qbwJv4AaDMcbkhNJwgKbqYrYdAyobc3LA2MsgeAGYKyLNIhIEbgU2DivzM9yzAUSkBreraI+HdTLGmAvukull7DveS3zaQguCTKqaAO4EHgV2Ag+p6nYRuVdE1qaLPQp0iMgO4Angb1S1w6s6GWOMFxbWVZBIKW+HL8rJuQlGHSMQkb8E/s/AN3vOhapuAjYN2/aZjGUF7ko/jDEmJy1vdK8w3paYRePA3AQNK7Ncq7EbyxlBLfCCiDyUvkBMvK6UMcbkknkzyigO+vhNJDcnsx81CFT1H3AHcL8N3A7sEpEvisgcj+tmjDE5IRzwM7umhGePFUG4Eg69mu0qnZMxjRGku3AOpR8JoAr4iYj8s4d1M8aYnHHJ9DL2n4ySyMEB41GDQEQ+LiJbgX8GfgMsUtWPAcuB93lcP2OMyQlL6itJppRDRXPduQlSyWxXaczGckHZFOBmVX0rc6OqpkTkD72pljHG5JaBAePtqUbqE33ut4emXpzlWo3NWLqGHgGOD6yISLmIrAJQ1Z1eVcwYY3LJxbWllIb8/LZ3prshhwaMxxIE/xvI/FJsJL3NGGNMWsDvY87UEjYfr0rPTZA74wRjCQJJDxYDbpcQ2b9HkTHGTDrzZpSz92ScZM0leRcEe0Tkr0QkkH58HLsNhDHGnGZJQwUphSPFF+ddEHwUeAfuDeMGbiW9zstKGWNMLmppmgLAazRBzxHozo25CUbt4klPFnPrBNTFGGNy2pyaEiqKAjzXV8c14J4VlNVmu1qjGsu9hsLAh4EFQHhgu6p+yMN6GWNMznEch4umlfL4iWncDe43h+Zel+1qjWosXUPfB6YD7wKexJ1XoNvLShljTK6aP6OcXZ0OqYrcmZtgLEFwkar+P0CPqn4XuJHTp5w0xhgDLG2oRIGOstwZMB5LEMTTzydFZCFQAUzzrkrGGJO7WprcK4zfkGboaINYT5ZrNLqxBMF6EakC/gF3hrEdwJc8rZUxxuSoxuoSqooDvBCtAxQO78h2lUZ11iAQEQfoUtUTqrpZVWer6jRV/cZYdp6ev+B1EWkTkbtHeP12ETkqIi+nH3eMsx3GGDNpzK0t48nO6e5KDtxq4qxBkL6K+G/Hs2MR8QH3AzcA84HbRGT+CEV/pKpL049vjedYxhgzmSyYWc5LXaWkwpU5MU4wlq6h/xKRvxaRBhGZMvAYw/tWAm2qukdVY8AG4Kbzqq0xxuSApQ2VgHCy/NKcCIKx3DPo/ennv8jYpsDsUd5XB+zPWB+4Knm494nI1cAbwCdVdf/wAiKyjvTVzLW1tbS2to6h2qeLRCLjfm+usjYXBmvzJBNzb8/2Sm81V/b+iqee+DWI77x361Wbx3JlcfMFP+opPwd+qKr9IvJnwHeB3x+hDuuB9QAtLS26Zs2acR2stbWV8b43V1mbC4O1efL5x+d/xWvB+fxe5BesWdhwQeYm8KrNY7my+E9H2q6q3xvlrQeAhoz1+vS2zH10ZKx+C3cWNGOMyXkX15ax+fB0/gzcAeNJPEnNWMYIVmQ8rgI+B6wdw/teAOaKSLOIBHHvV7Qxs4CIzMhYXQvYRDfGmLywsK6c5yNT0RyYm2AsXUN/mbkuIpW4A7+jvS8hIncCjwI+4AFV3S4i9wJbVHUj8FcishZI4M6Cdvu5N8EYYyafZQ1VrMdPd9lFlOd6EIygBxjTuIGqbgI2Ddv2mYzlTwOfHkcdjDFmUls1uxqAvYHZLD70fJZrc3ZjGSP4Oe63hMDtSpoPPORlpYwxJtdNKQlSWx7i5VgDi3seducmmKS3pB7LGcF9GcsJ4C1VbfeoPsYYkzcuqS3j6bdn8KcwqecmGMtg8T7gOVV9UlV/A3SISJOntTLGmDywsK6C3/bMdFcm8a0mxhIEPwZSGevJ9DZjjDFnsbyxim6K6S2pn9TfHBpLEPjTt4gAIL0c9K5KxhiTH1akb0m9Pzgn54PgaPorngCIyE3AMe+qZIwx+aG8KMjMijDbErMm9dwEYwmCjwL/t4jsE5F9wN+Be7GcMcaYs7tkRhnP9MxkMs9NMJYLynYDq0WkNL0e8bxWxhiTJxbXVfLj1+ogjDtg3LAi21U6zahnBCLyRRGpVNWIqkZEpEpEPj8RlTPGmFy3vLGKt6kmFqiYtOMEY+kaukFVTw6sqOoJ4N3eVckYY/LH8sYqBOHt8EU5HQQ+EQkNrIhIERA6S3ljjDFpJSE/9VVFbE/NgsPbIZXMdpVOM5Yg+AHwaxH5cHpO4V/hzhtgjDFmDC6dUc5ve+sg0Qcdu7NdndOMGgSq+iXg88A84BLcu4k2elwvY4zJG0vqK9gSrXdXJuEVxmM5IwA4jHvjuT/CnUHM5g0wxpgxWtE0hd06k6QTmJTjBGf8+qiIXAzcln4cA34EiKpeM0F1M8aYvLC4vpKk+DkSambGJAyCs50RvIb71/8fquqVqnkKVSQAABUtSURBVPo13PsMjZmIXC8ir4tIm4jcfZZy7xMRFZGWc9m/McbkgqKgj1lTitlJ46Q8IzhbENwMHASeEJFvisi1gIx1xyLiA+4HbsCdw+A2EZk/Qrky4OPAc+dScWOMySXzZ5bzfF8d9Bxx5yaYRM4YBKr6M1W9FbgUeAL4BDBNRP63iLxzDPteCbSp6p70jeo2ADeNUO4fgS8B0XOuvTHG5IilDZW82N/grkyys4Kx3GKiB3gQeFBEqnAHjP8OeGyUt9YB+zPW24FVmQVE5DKgQVV/ISJ/c6Ydicg6YB1AbW0tra2to1V7RJFIZNzvzVXW5sJgbZ78/J1Jdqr7hcs9z/yMfQfOfaZgr9p8TjVJX1W8Pv04LyLiAF9hDBPWq+rgMVtaWnTNmjXjOmZrayvjfW+usjYXBmvz5Hd5IskXnnuUE8GZzC7uYfY46u5Vm8f69dHxOAA0ZKzXp7cNKAMWAq0ishdYDWy0AWNjTD4K+X00V5fwujRNuq4hL4PgBWCuiDSLSBC4Fdg48KKqdqpqjao2qWoT8CywVlW3eFgnY4zJmnkzy9gSrUcn2dwEngWBqiaAO3GvRN4JPKSq20Xk3syJbowxplAsa6ji5XgDMsnmJjj30YpzoKqbgE3Dtn3mDGXXeFkXY4zJthVNVXwrlb5DzySam8DLriFjjDEZLplezhGnhl5f2aQaJ7AgMMaYCRL0O8yZWsZup9mCwBhjCtWCmeVsjTWgk2huAgsCY4yZQJc1VrEt3oBMorkJLAiMMWYCLW+sYoc2uSuTZG4CCwJjjJlAc6eVst+pJyH+STNOYEFgjDETyO9zaJxWyT5nlgWBMcYUqkX1Fbwcb0AtCIwxpjBdNquKV5KzkEkyN4EFgTHGTLDLZlWyI9XkrkyCswILAmOMmWCzp5ayx9/krkyCbw5ZEBhjzATzOcKM2ukccmrtjMAYYwrVoroKXknMmhQDxhYExhiTBcsbq3g1OQsmwdwEFgTGGJMFSxoq2aGNk2JuAgsCY4zJgubqEvb4ZrsrWR4w9jQIROR6EXldRNpE5O4RXv+oiLwiIi+LyNMiMt/L+hhjzGThOEL59Ga6pSTrA8aeBYGI+ID7gRuA+cBtI3zQP6iqi1R1KfDPwFe8qo8xxkw2Sxoq2Z5sJJWvQQCsBNpUdY+qxoANwE2ZBVS1K2O1BFAP62OMMZPK8sYqtqca4dCrWZ2bwMs5i+uA/Rnr7cCq4YVE5C+Au4Ag8Psj7UhE1gHrAGpra2ltbR1XhSKRyLjfm6uszYXB2pyb+npT7Eg14iSjPPfLH9JXXH/W8l612dPJ68dCVe8H7heR/w78A/CBEcqsB9YDtLS06Jo1a8Z1rNbWVsb73lxlbS4M1ubcpKr86LldAKyaVQQL15y1vFdt9rJr6ADQkLFen952JhuA93hYH2OMmVREhOD0ecTJ7twEXgbBC8BcEWkWkSBwK7Axs4CIzM1YvRHY5WF9jDFm0lk4q4ZdqTpSB7P3FVLPgkBVE8CdwKPATuAhVd0uIveKyNp0sTtFZLuIvIw7TnBat5AxxuSzy2a5A8bJt7MXBJ6OEajqJmDTsG2fyVj+uJfHN8aYyW5RfQXf1kb+qG+zOzdBWe2E18GuLDbGmCyqqyzircAcd+VwdsYJLAiMMSaLRARnxiJ3JUsDxhYExhiTZRc31rNfp2ZtnMCCwBhjsmxJQyU7Uo3ED/wuK8e3IDDGmCxbXF/BjlQjoc49WZmbwILAGGOybHp5mH3BOe7cBEd2TvjxLQiMMSbLRASdPjBgPPHjBBYExhgzCcxquphOLc7KOIEFgTHGTAJLZlWxI9VEf7sFgTHGFKRFdRXs0EZCHTsnfG4CCwJjjJkEppWH2R+aQyAVheN7JvTYFgTGGDNJpKYtdBcmeMDYgsAYYyaJabOXEFPfhI8TWBAYY8wksXBWDbu0nr59L0/ocS0IjDFmklhU515hHDy2fUKPa0FgjDGTRHVpiPbQRRTHjrlzE0wQTyemEZHrgX8BfMC3VPWfhr1+F3AHkACOAh9S1bfO9TjxeJz29nai0ehZy1VUVLBz58Rfvp1NmW0Oh8PU19cTCASyXCtjzJkkpy2Eg7hzE0zQJDWeBYGI+ID7gT8A2oEXRGSjqu7IKPYS0KKqvSLyMeCfgfef67Ha29spKyujqakJETljue7ubsrKys519zltoM2qSkdHB+3t7TQ3N2e7WsaYM6icfRkchL79v6Poousm5Jhedg2tBNpUdY+qxoANwE2ZBVT1CVXtTa8+C9SP50DRaJTq6uqzhkChExGqq6tHPWsyxmTXpU0N7E9NJbL3xQk7ppddQ3XA/oz1dmDVWcp/GHhkpBdEZB2wDqC2tpbW1tYhr1dUVBCJREatUDKZpLu7e9Ry+WR4m6PR6Gk/v3wTiUTyvo3DWZvzRySm9GgjSw+8dFr7vGqzp2MEYyUifwy0AL830uuquh5YD9DS0qJr1qwZ8vrOnTvH1OVTyF1DA8LhMMuWLctijbzX2trK8H8j+c7anF++9fwG/iCxldp3rIBgyeB2r9rsZdfQAaAhY70+vW0IEbkO+Htgrar2e1ifnNLU1MSxY8eyXQ1jTBYkpi7AmcC5CbwMgheAuSLSLCJB4FZgY2YBEVkGfAM3BI54WJcJpaqkUqlsV8MYk6PKmtyz9p63XpqQ43nWNaSqCRG5E3gU9+ujD6jqdhG5F9iiqhuB/wmUAj9OD/TuU9W153Pce36+nR1vd434WjKZxOfznfM+588s57P/14Kzltm7dy/vete7WLVqFVu3bmXlypW88sor9PX1ccstt3DPPfcA7l/6H/jAB/j5z39OPB7nxz/+MZdeeikdHR3cdtttHDhwgMsvvxxVHdz3V77yFR544AEA7rjjDj7xiU+wd+9err/+elavXs0zzzzDihUr+OAHP8hnP/tZjhw5wg9+8ANWrlx5zm01xmRf85xL6XymmJ43X6TkCu+P5+kFZaq6SVUvVtU5qvqF9LbPpEMAVb1OVWtVdWn6cV4hkG27du3iz//8z9m+fTtf/vKX2bJlC9u2bePJJ59k27ZTN5GqqanhxRdf5GMf+xj33XcfAPfccw9XXnkl27dv573vfS/79u0DYOvWrfz7v/87zz33HM8++yzf/OY3eekl96+EtrY2PvWpT/Haa6/x2muv8eCDD/L0009z33338cUvfnHifwDGmAtiYX0lO1JNOIdfmZDjTYrB4gvpbH+5ez1Y3NjYyOrVqwF46KGHWL9+PYlEgoMHD7Jjxw4WL14MwM033wzA8uXL+elPfwrA5s2bB5dvvPFGqqqqAHj66ad573vfS0lJyeB7n3rqKdauXUtzczOLFrnT2y1YsIBrr70WEWHRokXs3bvXs3YaY7xVHg6wPzSHyyK/cucmcM69J+Nc2C0mLqCBD+s333yT++67j1//+tds27aNG2+8ccj390OhEAA+n49EIjHu4w3sB8BxnMF1x3HOa7/GmOyL1SwgpBMzN4EFgQe6urooKSmhoqKCw4cP88gjI14eMcTVV1/Ngw8+CMAjjzzCiRMnALjqqqv42c9+Rm9vLz09Pfznf/4nV111laf1N8ZkX/GspQB0ven9hWV51zU0GSxZsoRly5Zx6aWX0tDQwBVXjD7a89nPfpbbbruNBQsW8I53vINZs2YBcNlll3H77bcPDvzecccdLFu2zLp+jMlzDRcvI/acjxN7tlK+4pzvvHNOLAgukKamJl599dXB9e985zsjlsv8AG9paRm8SrC6uprHHntsxPfcdddd3HXXXWM+3vDXjDG5Z36DOzdBySHvB4yta8gYYyahkpCf/cE5VHa95vmxLAiMMWaS6qteQGXyuOdzE1gQGGPMJBWuXwLACY8HjC0IjDFmkppxyQoAju3a4ulxLAiMMWaSuqSpgf06leTBbaMXPg8WBMYYM0kVBX3sC8yh/KS3dyG1ILiA2tvbuemmm5g7dy5z5szh4x//OLFYjNbWVioqKli6dCmLFy/muuuu48gR92ar3/nOd5g6dSrLli1j7ty5vOtd7+KZZ57JckuMMZNFT9U8pifa0f7RJ98aLwuCC0RVufnmm3nPe97Drl27eOONN4hEIvz93/894F4h/PLLL7Nt2zZWrFjB/fffP/je97///bz00kvs2rWLu+++m5tvvnlwwnljTGEL1C/BQTm653eeHSP/Lih75G44wwUYRckE+MbR5OmL4IZ/OmuRxx9/nHA4zAc/+EHAvY/QV7/6VZqbm7nmmmsGy6kq3d3dXHTRRSPu55prrmHdunWsX7+er371q+deV2NMXpk2dwW8BEd3PQ/l3swuaGcEF8j27dtZvnz5kG3l5eXMmjWLtrY2nnrqKZYuXcqsWbP4r//6Lz70oQ+dcV+XXXYZr73m/UUkxpjJb85Fl9KpJcTavRsw9vSMQESuB/4Fd2Kab6nqPw17/WrgfwGLgVtV9SfnfdCz/OXel8U5i6+66ioefvhhAL70pS/xt3/7t3z9618fsWzmpDTGmMIWDvp5IzCb0pM76fToGJ6dEYiID7gfuAGYD9wmIvOHFdsH3A486FU9Jsr8+fPZunXrkG1dXV3s27fvtG6gtWvXsnnz5jPu66WXXmLevHme1NMYk3u6Ky+lPrYHTXlze3kvu4ZWAm2qukdVY8AG4KbMAqq6V1W3ATk/we+1115Lb28v3/ve9wB3WsxPfepT3H777RQXFw8p+/TTTzNnzpwR9/Pkk0+yfv16PvKRj3heZ2NMbnBmLKaIfqInDnqyfy+7huqA/Rnr7cCq8exIRNYB6wBqa2sH79g5oKKigu7u7lH3k0wmx1RuvL7//e9z1113cc8995BKpXjnO9/Jpz/9aZ5//nmeeuopFi9ejKpSXl7O1772Nbq7u4lGo2zYsIHNmzfT29tLY2Mj3//+96mvr78gdR3e5mg0etrPL99EIpG8b+Nw1ub81hVz/5jsOfSaJ20Wr/qjReQW4HpVvSO9/ifAKlW9c4Sy3wEeHssYQUtLi27ZMvRy6507d46pK8XrqSono+FtHuvPKpe1trayZs2abFdjQlmb81usP8rO/7WWvdP+gJs++Dfj2oeIbFXVlpFe87Jr6ADQkLFen95mjDHmHARDYZb83WNUNK/wZP9eBsELwFwRaRaRIHArsNHD4xljjBkHz4JAVRPAncCjwE7gIVXdLiL3ishaABFZISLtwB8B3xCR7edxvAtR7bxmPyNjzEg8vY5AVTcBm4Zt+0zG8gu4XUbnJRwO09HRQXV1NSJyvrvLS6pKR0cH4XA421UxxkwyeXGLifr6etrb2zl69OhZy0Wj0YL7IMxsczgcpr7+vHPXGJNn8iIIAoEAzc3No5ZrbW1l2TJv7tUxWRVim40x58buNWSMMQXOgsAYYwqcBYExxhQ4z64s9oqIHAXeGufba4BjF7A6ucDaXBiszYXhfNrcqKpTR3oh54LgfIjIljNdYp2vrM2FwdpcGLxqs3UNGWNMgbMgMMaYAldoQbA+2xXIAmtzYbA2FwZP2lxQYwTGGGNOV2hnBMYYY4axIDDGmAKXl0EgIteLyOsi0iYid4/wekhEfpR+/TkRaZr4Wl5YY2jzXSKyQ0S2icivRaQxG/W8kEZrc0a594mIikjOf9VwLG0Wkf+W/l1vF5EHJ7qOF9oY/m3PEpEnROSl9L/vd2ejnheKiDwgIkdE5NUzvC4i8q/pn8c2EbnsvA+qqnn1AHzAbmA2EAR+B8wfVubPga+nl28FfpTtek9Am68BitPLHyuENqfLlQGbgWeBlmzXewJ+z3OBl4Cq9Pq0bNd7Atq8HvhYenk+sDfb9T7PNl8NXAa8eobX3w08AgiwGnjufI+Zj2cEK4E2Vd2jqjFgA3DTsDI3Ad9NL/8EuFZyeyKDUdusqk+oam969VkuwDwQWTaW3zPAPwJfAqITWTmPjKXNHwHuV9UTAKp6ZILreKGNpc0KlKeXK4C3J7B+F5yqbgaOn6XITcD31PUsUCkiM87nmPkYBHXA/oz19vS2EcuoO5NaJ1A9IbXzxljanOnDuH9R5LJR25w+ZW5Q1V9MZMU8NJbf88XAxSLyGxF5VkSun7DaeWMsbf4c8Mfp2Q43AX85MVXLmnP9/z6qvJiPwIydiPwx0AL8Xrbr4iURcYCvALdnuSoTzY/bPbQG96xvs4gsUtWTWa2Vt24DvqOqXxaRy4Hvi8hCVU1lu2K5Ih/PCA4ADRnr9eltI5YRET/u6WTHhNTOG2NpMyJyHfD3wFpV7Z+gunlltDaXAQuBVhHZi9uXujHHB4zH8ntuBzaqalxV3wTewA2GXDWWNn8YeAhAVX8LhHFvzpavxvT//VzkYxC8AMwVkWYRCeIOBm8cVmYj8IH08i3A45oehclRo7ZZRJYB38ANgVzvN4ZR2qyqnapao6pNqtqEOy6yVlW3ZKe6F8RY/m3/DPdsABGpwe0q2jORlbzAxtLmfcC1ACIyDzcIzj5vbW7bCPxp+ttDq4FOVT14PjvMu64hVU2IyJ3Ao7jfOHhAVbeLyL3AFlXdCHwb9/SxDXdQ5tbs1fj8jbHN/xMoBX6cHhffp6prs1bp8zTGNueVMbb5UeCdIrIDSAJ/o6o5e7Y7xjZ/CvimiHwSd+D49lz+w05Efogb5jXpcY/PAgEAVf067jjIu4E2oBf44HkfM4d/XsYYYy6AfOwaMsYYcw4sCIwxpsBZEBhjTIGzIDDGmAJnQWCMMQXOgsCYC0RE7k1ftGdMTrGvjxpjTIGzMwJjzkBEmkRkp4h8M31v/8dEpEhElqZv6LZNRP5TRKrS5b8jIrekl/8pY/6H+9LbporIf4jIC+nHFdlsnzEDLAiMObu5uLd1XgCcBN4HfA/4O1VdDLyCe+XnIBGpBt4LLEiX+Xz6pX8BvqqqK9L7+dbENMGYs8u7W0wYc4G9qaovp5e3AnOASlV9Mr3tu8CPh72nE3f+g2+LyMPAw+nt1wHzM6a+KBeRUlWNeFZ7Y8bAgsCYs8u8S2sSqBztDen746zEvRHaLcCdwO/jnoGvVtV8mCTH5BHrGjLm3HQCJ0TkqvT6nwBPZhYQkVKgQlU3AZ8ElqRfeoyMSVNEZKn31TVmdHZGYMy5+wDwdREpxr3F8/C7P5YB/5+IhHHnlb0rvf2vgPtFZBvu/73NwEcnpsrGnJl9fdQYYwqcdQ0ZY0yBsyAwxpgCZ0FgjDEFzoLAGGMKnAWBMcYUOAsCY4wpcBYExhhT4P5/KhFrGa5J0FAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(amounts, random_mean, label='random')\n",
    "plt.fill_between(amounts, random_mean-random_std, random_mean+random_std, alpha=0.3)\n",
    "\n",
    "plt.plot(amounts, List_of_OBD_score, label='OBD')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlabel('noise')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Optimal Brain Damage позволяет удалять больше параметров (около 80% против окола 70%) без значимой потери точности. Следовательно данный метод является намного лучше чем произвольное удаление параметров.\n",
    "\n",
    "Стоит заметить, что произвольное удаление параметров также позволяет удалять большое количество параметров из модели, это связано с тем, что большое количество точек в картиинках mnist это фон (значит данный признак нулевой). И все точки из границы изображения являются не нужными, что и позволяет убрать большое количество признаков."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
