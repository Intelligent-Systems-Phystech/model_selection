{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDUVA7WCIWde"
   },
   "outputs": [],
   "source": [
    "from zlib import crc32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_ecEqR2qIWdl",
    "outputId": "adafe6ab-aac0-422c-8176-5f4ce4936d75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crc32('грабовой'.lower().encode('utf-8'))%5+1, crc32('grabovoy'.lower().encode('utf-8'))%3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRw7tB2F_kvg"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5mJHz-6BGj2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-xH14pMIWdr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYh-uWuv-xsj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezKBGTrTIWdy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "eOVW8XKdIWd2",
    "outputId": "72a25541-26db-4000-8817-359f6e5dbd2a"
   },
   "outputs": [],
   "source": [
    "MNIST = datasets.MNIST('./mnist', train=False, download=True, transform=None)\n",
    "X_test, Y_test = MNIST.test_data, MNIST.test_labels\n",
    "\n",
    "MNIST = datasets.MNIST('./mnist', train=True, download=True, transform=None)\n",
    "X_train, Y_train = MNIST.train_data, MNIST.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MECG-LbtIWd4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([X_train.shape[0], -1]).float()\n",
    "X_test = X_test.reshape([X_test.shape[0], -1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CM1Tt6gsIWd7",
    "outputId": "0bf794f6-077e-441b-beef-948fddcfccb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c50HSjxgIWd9"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IELWT_-JnExw"
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# https://github.com/mariogeiger/hessian #\n",
    "##########################################\n",
    "#                                        #\n",
    "# Данные функции были взяты из интернета #\n",
    "#                                        #\n",
    "##########################################\n",
    "\n",
    "def gradient(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False):\n",
    "    '''\n",
    "    Compute the gradient of `outputs` with respect to `inputs`\n",
    "    gradient(x.sum(), x)\n",
    "    gradient((x * y).sum(), [x, y])\n",
    "    '''\n",
    "    if torch.is_tensor(inputs):\n",
    "        inputs = [inputs]\n",
    "    else:\n",
    "        inputs = list(inputs)\n",
    "    grads = torch.autograd.grad(outputs, inputs, grad_outputs,\n",
    "                                allow_unused=True,\n",
    "                                retain_graph=retain_graph,\n",
    "                                create_graph=create_graph)\n",
    "    grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
    "    return torch.cat([x.contiguous().view(-1) for x in grads])\n",
    "\n",
    "def hessian(output, inputs, out=None, allow_unused=False, create_graph=False):\n",
    "    '''\n",
    "    Compute the Hessian of `output` with respect to `inputs`\n",
    "    hessian((x * y).sum(), [x, y])\n",
    "    '''\n",
    "    assert output.ndimension() == 0\n",
    "\n",
    "    if torch.is_tensor(inputs):\n",
    "        inputs = [inputs]\n",
    "    else:\n",
    "        inputs = list(inputs)\n",
    "\n",
    "    n = sum(p.numel() for p in inputs)\n",
    "    if out is None:\n",
    "        out = output.new_zeros(n, n)\n",
    "\n",
    "    ai = 0\n",
    "    for i, inp in enumerate(inputs):\n",
    "        [grad] = torch.autograd.grad(output, inp, create_graph=True, allow_unused=allow_unused)\n",
    "        grad = torch.zeros_like(inp) if grad is None else grad\n",
    "        grad = grad.contiguous().view(-1)\n",
    "\n",
    "        for j in range(inp.numel()):\n",
    "            if grad[j].requires_grad:\n",
    "                row = gradient(grad[j], inputs[i:], retain_graph=True, create_graph=create_graph)[j:]\n",
    "            else:\n",
    "                row = grad[j].new_zeros(sum(x.numel() for x in inputs[i:]) - j)\n",
    "\n",
    "            out[ai, ai:].add_(row.type_as(out))  # ai's row\n",
    "            if ai + 1 < n:\n",
    "                out[ai + 1:, ai].add_(row[1:].type_as(out))  # ai's column\n",
    "            del row\n",
    "            ai += 1\n",
    "        del grad\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим модель логистической регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sU4N4hkIWd-"
   },
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, input_dim = 20, output_dim = 10, device = 'cpu'):\n",
    "        super(LogReg, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = input\n",
    "        out = F.relu(out)\n",
    "        return self.linear(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tL9H_7P_IWd_"
   },
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определим все функции для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veyRL9LKIWd_"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output = model(batch_of_x)\n",
    "        \n",
    "        loss = loss_function(output, batch_of_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     \n",
    "        return\n",
    "    \n",
    "def train_epoch(train_generator, model, loss_function, optimizer):\n",
    "    model.train()\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "\n",
    "    return\n",
    "\n",
    "def trainer(count_of_epoch, \n",
    "            batch_size, \n",
    "            dataset,\n",
    "            model, \n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            progress = None\n",
    "           ):\n",
    "    iterations = range(count_of_epoch)\n",
    "    if progress is not None:\n",
    "        iterations = progress(iterations)\n",
    "\n",
    "    for it in iterations:\n",
    "        optima = optimizer\n",
    "\n",
    "        batch_generator = DataLoader(dataset = dataset, batch_size = batch_size, shuffle=True)\n",
    "        \n",
    "        train_epoch(train_generator = batch_generator, model = model, loss_function = loss_function, optimizer = optima)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYhvcbLmIWeA"
   },
   "source": [
    "# Переопределеный оптимизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переопределим оптимизатор, чтобы оптимизировать только те переменые, которые не были удалены из модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7J43Um9tIWeA"
   },
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adam, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "            \n",
    "# ==================================================\n",
    "# Additition function\n",
    "    def get_masks(self, kind = 'prune'):\n",
    "        list_of_mask = []\n",
    "        LIST_prune = []\n",
    "        mask_vector = None\n",
    "        if kind == 'prune':\n",
    "            for group in self.param_groups:\n",
    "                 for p in group['params']:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'prune' not in param_state:\n",
    "                        param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                    p_vector = p.view(-1)\n",
    "                    prune_vector = param_state['prune'].view(-1)\n",
    "                    LIST_prune.append(prune_vector)\n",
    "        mask_vector = torch.cat(LIST_prune)\n",
    "        return mask_vector\n",
    "\n",
    "    def prune(self, amount = 0.1, method='random', **argv):\n",
    "        if method == 'random':\n",
    "            for group in self.param_groups:\n",
    "                 for p in group['params']:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'prune' not in param_state:\n",
    "                        param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                    p_vector = p.view(-1)\n",
    "                    prune_vector = param_state['prune'].view(-1)\n",
    "                    if int(amount*len(p_vector)) > 0:\n",
    "                        prune_vector[torch.randperm(p_vector.shape[0])[:int(amount*len(p_vector))]] = 0\n",
    "                        p_vector.data.mul_(prune_vector)\n",
    "\n",
    "        elif method == 'OBD':\n",
    "            if argv['hessian'] is None:\n",
    "                pass\n",
    "            else:\n",
    "                for group in self.param_groups:\n",
    "                    for p, h in zip(group['params'], argv['hessian']):\n",
    "                        param_state = self.state[p]\n",
    "                        if 'prune' not in param_state:\n",
    "                            param_state['prune'] = torch.ones_like(p)\n",
    "\n",
    "                        p_vector = p.view(-1)\n",
    "                        score = (p*h).view(-1)\n",
    "                        prune_vector = param_state['prune'].view(-1)\n",
    "                        if int(amount*len(p_vector)) > 0:\n",
    "                            prune_vector[torch.sort(score)[1][:int(amount*len(p_vector))]] = 0\n",
    "                            p_vector.data.mul_(prune_vector)\n",
    "\n",
    "            pass\n",
    "    \n",
    "    def deprune(self):\n",
    "        for group in self.param_groups:\n",
    "             for p in group['params']:\n",
    "                param_state = self.state[p]\n",
    "                param_state['prune'] = torch.ones_like(p)\n",
    "# ==================================================\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                    \n",
    "# ==================================================\n",
    "# Addition in each step\n",
    "                d_p = p.grad.data.detach()\n",
    "                param_state = self.state[p]\n",
    "    \n",
    "                if 'prune' in param_state:\n",
    "                    prune = param_state['prune']\n",
    "                else:\n",
    "                    prune = torch.ones_like(p)\n",
    "                    param_state['prune'] = prune\n",
    "# ==================================================                   \n",
    "                    \n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if 'step' not in state:\n",
    "                    state['step'] = 0\n",
    "                # Exponential moving average of gradient values\n",
    "                if 'exp_avg' not in state:\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                # Exponential moving average of squared gradient values\n",
    "                if 'exp_avg_sq' not in state:\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                if amsgrad:\n",
    "                    # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                    if 'max_exp_avg_sq' not in state:\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                \n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad.add_(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                if amsgrad:\n",
    "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    # Use the max. for normalizing running avg. of gradient\n",
    "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                else:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "\n",
    "                    \n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                step_size = group['lr'] * (bias_correction2**(0.5)) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, prune*exp_avg, denom)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-de7oKsIWeB"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SpRX1OD_IWeC",
    "outputId": "9b7c81cd-09a0-4bf1-ca1c-d2fe12ae0b12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47AcefhNIWeE"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2Pte2nfIWeF"
   },
   "outputs": [],
   "source": [
    "TRAIN = TensorDataset(X_train.to(device), Y_train.to(device))\n",
    "TEST = TensorDataset(X_test.to(device), Y_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAYSy-dZIWeG"
   },
   "outputs": [],
   "source": [
    "model = LogReg(input_dim=X_train.shape[1], output_dim = 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcykU8MDIWeG"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VXz5GEQ9IWeI",
    "outputId": "558bc9c6-5e10-457e-d17a-dadd6bfb5894"
   },
   "outputs": [],
   "source": [
    "# trainer(count_of_epoch = 100,\n",
    "#         batch_size = 64,\n",
    "#         dataset = TRAIN,\n",
    "#         model = model,\n",
    "#         loss_function = loss_function,\n",
    "#         optimizer = optimizer,\n",
    "#         progress = tqdm\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n2QdIc7-FnH"
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'train_model.sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "An5G7SSRIWeJ"
   },
   "outputs": [],
   "source": [
    "output = model(TRAIN[:][0])\n",
    "\n",
    "loss = loss_function(output, TRAIN[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ng4dPeRmtEln"
   },
   "outputs": [],
   "source": [
    "def resize_hess(model, hess):\n",
    "    bias = 0\n",
    "    new_hess = []\n",
    "    for p in model.parameters():\n",
    "        p_size = torch.tensor(p.size()).prod()\n",
    "        new_hess.append(hess[bias:bias+p_size].view_as(p))\n",
    "        bias+=p_size\n",
    "    return new_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sYNkYmHpnLAB",
    "outputId": "a1a1dd4d-a3d8-44aa-d405-6ee0a1b0a3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 2s, sys: 4.63 s, total: 24min 7s\n",
      "Wall time: 24min 8s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# hess = hessian(loss, model.parameters())\n",
    "\n",
    "# hhs = torch.diag(hess)\n",
    "# hs = resize_hess(model, hhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jcPYBa7_NlM"
   },
   "outputs": [],
   "source": [
    "# with open('hess.pkl', 'wb') as f:\n",
    "#     pickle.dump(hs, f)\n",
    "\n",
    "with open('dump/hess.pkl', 'rb') as f:\n",
    "    hs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xobJxrVP_H6p"
   },
   "outputs": [],
   "source": [
    "# files.download('train_model.sv')\n",
    "# files.download('hess.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "Tp0v1YVi_gqB",
    "outputId": "7473626a-7d04-407c-ef9e-295132ebe64d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:04<00:00, 11.87s/it]\n",
      "100%|██████████| 10/10 [00:24<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "amounts = np.linspace(0, 1, 10)\n",
    "k_for_averaging = 5\n",
    "\n",
    "List_of_random_score = []\n",
    "for amount in tqdm(amounts):\n",
    "    List_of_score = []\n",
    "    for _ in range(k_for_averaging):\n",
    "        model.load_state_dict(torch.load('dump/train_model.sv'))\n",
    "        optimizer = Adam(model.parameters())\n",
    "        optimizer.prune(amount=amount, method='random', hessian=hs)\n",
    "\n",
    "        trainer(count_of_epoch = 2,\n",
    "            batch_size = 64,\n",
    "            dataset = TRAIN,\n",
    "            model = model,\n",
    "            loss_function = loss_function,\n",
    "            optimizer = optimizer\n",
    "        )\n",
    "\n",
    "        output = model(TEST[:][0])\n",
    "        output.sum(dim = 1)\n",
    "        answ = torch.argmax(torch.softmax(output, dim = 1), dim = 1)\n",
    "\n",
    "        List_of_score.append(float((TEST[:][1] == answ).sum())/TEST[:][1].shape[0])\n",
    "    List_of_random_score.append(List_of_score)\n",
    "  \n",
    "List_of_random_score = np.array(List_of_random_score)\n",
    "\n",
    "\n",
    "List_of_OBD_score = []\n",
    "for amount in tqdm(amounts):\n",
    "    model.load_state_dict(torch.load('dump/train_model.sv'))\n",
    "    optimizer = Adam(model.parameters())\n",
    "    optimizer.prune(amount=amount, method='OBD', hessian=hs)\n",
    "\n",
    "    trainer(count_of_epoch = 2,\n",
    "        batch_size = 64,\n",
    "        dataset = TRAIN,\n",
    "        model = model,\n",
    "        loss_function = loss_function,\n",
    "        optimizer = optimizer\n",
    "    )\n",
    "\n",
    "    output = model(TEST[:][0])\n",
    "    output.sum(dim = 1)\n",
    "    answ = torch.argmax(torch.softmax(output, dim = 1), dim = 1)\n",
    "\n",
    "    List_of_OBD_score.append(float((TEST[:][1] == answ).sum())/TEST[:][1].shape[0])\n",
    "  \n",
    "List_of_OBD_score = np.array(List_of_OBD_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYU8pQfjBKrV"
   },
   "outputs": [],
   "source": [
    "random_mean = np.mean(List_of_random_score, axis = 1)\n",
    "random_std = np.std(List_of_random_score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 5), (10, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_of_random_score.shape, List_of_random_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), (10,), (10,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_mean.shape, random_std.shape, List_of_OBD_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "oSJPNaJv9Z4o",
    "outputId": "19f929de-65a0-40bd-99e1-08f41433e495"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(amounts, random_mean, label='random')\n",
    "plt.fill_between(amounts, random_mean-random_std, random_mean+random_std, alpha=0.3)\n",
    "\n",
    "plt.plot(amounts, List_of_OBD_score, label='OBD')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Optimal Brain Damage позволяет удалять больше параметров (около 80% против окола 70%) без значимой потери точности. Следовательно данный метод является намного лучше чем произвольное удаление параметров.\n",
    "\n",
    "Стоит заметить, что произвольное удаление параметров также позволяет удалять большое количество параметров из модели, это связано с тем, что большое количество точек в картиинках mnist это фон (значит данный признак нулевой). И все точки из границы изображения являются не нужными, что и позволяет убрать большое количество признаков."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
