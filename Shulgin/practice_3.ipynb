{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zlib import crc32\n",
    "theory = crc32(\"Шульгин\".lower().encode(\"utf-8\"))%5+1\n",
    "practice = crc32(\"Shulgin\".lower().encode(\"utf-8\"))%3+1\n",
    "\n",
    "theory, practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task  \n",
    "Реализовать пример удаления параметров для логистической регрессии на\n",
    "MNIST и сравнить качество со случайным удалением параметров (ось X — процент удаленных\n",
    "параметров):  \n",
    "2) С использованием вариационного вывода (Graves, 2011);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", font_scale=1.5)\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
    "trainset = datasets.MNIST('./data/', download=True, train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST('./data/', download=True, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, features=784, classes=10):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        self.classes = classes\n",
    "        self.distr = MultivariateNormal(torch.zeros(self.features*self.classes), \n",
    "                                       precision_matrix=torch.eye(self.features*self.classes))\n",
    "        self.loc = nn.Parameter(torch.randn(features * classes))\n",
    "        self.var = nn.Parameter(torch.abs(torch.randn(features * classes)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.features)       \n",
    "        z = self.distr.sample().to(device)\n",
    "        w = self.loc + self.var * z\n",
    "        return torch.mm(x, w.view(self.features, self.classes))\n",
    "    \n",
    "    def value(self, x):\n",
    "        x = x.view(-1, self.features)\n",
    "        return torch.mm(x, self.loc.view(self.features, self.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = LogisticRegression().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2807/3750 [01:35<00:25, 37.53it/s]"
     ]
    }
   ],
   "source": [
    "for data, target in tqdm(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cross_entropy = criterion(model(data), target)\n",
    "    kl_divergence = 0.5 * (torch.sum(model.var) + torch.sum(model.loc * model.loc) - torch.sum(torch.log(model.var)))\n",
    "    loss = cross_entropy + kl_divergence\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_params(params, lam):\n",
    "    vb_params = deepcopy(params)\n",
    "    rand_params = deepcopy(params)\n",
    "    \n",
    "    lambdas = torch.abs(params['loc'] / params['var'])\n",
    "    mask = (lambdas < lam)\n",
    "    vb_params['loc'][mask] = 0\n",
    "    \n",
    "    pruned = mask.sum().float() / mask.shape[0]\n",
    "    \n",
    "    mask = mask.view(-1)[torch.randperm(mask.nelement())].view(mask.size())\n",
    "    rand_params['loc'][mask] = 0\n",
    "    \n",
    "    return vb_params, rand_params, pruned\n",
    "\n",
    "def calculate_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = torch.argmax(model.value(data), dim=-1)\n",
    "        correct += (output == target).float().sum()\n",
    "        total += len(output)\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_params = deepcopy(model.state_dict())\n",
    "\n",
    "x = (np.exp(np.linspace(0, 15, 14)) - 1) / 1e4\n",
    "random_accs = []\n",
    "vb_accs = []\n",
    "pruned = []\n",
    "\n",
    "for lam in tqdm(x):\n",
    "    pruned_params, rand_parms, deleted = prune_params(source_params, lam)\n",
    "    pruned.append(deleted)\n",
    "    \n",
    "    model.load_state_dict(rand_parms)\n",
    "    model.eval()\n",
    "    random_accs.append(calculate_accuracy(test_loader, model))\n",
    "    \n",
    "    model.load_state_dict(pruned_params)\n",
    "    model.eval()\n",
    "    vb_accs.append(calculate_accuracy(test_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(pruned, vb_accs, label='Variational Bayes')\n",
    "plt.plot(pruned, random_accs, label='Random pruning')\n",
    "plt.xlabel(\"% of pruned params\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Random vs VB\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графика, вариационный вывод показывает гораздо более хорошие показатели: средняя точность падает весьма слабо при удалении ~70% параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
